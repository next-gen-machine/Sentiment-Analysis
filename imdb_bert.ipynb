{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f867ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4176172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Concatenate,Dense,Input,Embedding,Bidirectional,LSTM,GRU\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044956b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c584b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(\"/data2/scratch/rohitr/datasets/IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba741be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'negative':0,'positive':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad805d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['sentiment'] = imdb_df['sentiment'].apply(lambda x : d.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5a052c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305babba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(imdb_df['review'],imdb_df['sentiment'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c5f092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 20:04:30.816825: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-02 20:04:33.894027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38418 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a371aa2050498fb7c69524a34abbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3c0d8bb32a44f087823478f7bcab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b41c46d16b841cf9ec3479f2d2500fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489a5512c6144fe4b7876e6c746ba730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063787ae9af44e9ebd70ea05f1c391a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 20:05:36.543620: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,TFBertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "bert = TFBertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f9fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input (takes some time) \n",
    "# here tokenizer using from bert-base-cased\n",
    "x_train = tokenizer(\n",
    "    text=X_train.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "x_test = tokenizer(\n",
    "    text=X_test.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0678de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids']\n",
    "attention_mask = x_train['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9b176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "y = Dense(1,activation = 'sigmoid')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeabaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "095d614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = CategoricalCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "334cbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc6f52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 20:11:37.661764: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "625/625 [==============================] - 211s 233ms/step - loss: 0.3359 - acc: 0.8504 - val_loss: 0.2786 - val_acc: 0.8804\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 0.2292 - acc: 0.9069 - val_loss: 0.2762 - val_acc: 0.8840\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
    "    ),\n",
    "  epochs=2,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31e48b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 0.1903 - acc: 0.9267 - val_loss: 0.2788 - val_acc: 0.8855\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 0.1673 - acc: 0.9362 - val_loss: 0.2925 - val_acc: 0.8848\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
    "    ),\n",
    "  epochs=2,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d23f69b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00948634], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
    "predicted_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b57d1bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 30s 95ms/step - loss: 0.2925 - acc: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2925480306148529, 0.8848000168800354]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.argmax(predicted_raw, axis = 1)\n",
    "#y_true = df_test.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff83c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
